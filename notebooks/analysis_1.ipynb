{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd48570-438f-4a26-8820-48b3327b3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import torch\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import DataLoader\n",
    "project_root = Path.cwd().parent  \n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "from src.data_preprocessing.normalization import XarrayNormalizer\n",
    "from src.data_preprocessing.create_dataloaders import SweDataset\n",
    "from src.data_preprocessing.split_data import split_by_time\n",
    "from src.utils.utils import (write_to_netcdf, data_split, unscale_pred, load_scalers)\n",
    "from src.training.trainer import evaluate_model\n",
    "from src.models.swe_net import SWE_NET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149fdf95-7287-4b14-8cdd-94072995fbc5",
   "metadata": {},
   "source": [
    "# DATA SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a98031-f026-4a3d-a8b3-4c05432e22b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361, 390, 348)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup test set for prediction\n",
    "\n",
    "sequence_length = 5\n",
    "start = f'2015-10-{sequence_length + 1}'\n",
    "end = '2016-09-30'\n",
    "\n",
    "true_labels = data_split('2016', '2016')['SNOW'].sel(XTIME=slice(start, end))\n",
    "true_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb92121-3d6c-4321-956a-cb32a078ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/bsuscratch/stanleyakor/swe_emulator/modis'\n",
    "\n",
    "ds1 = xr.open_dataset(base + '/wrf_features_june_30_2025.nc')[['SNOWNC_CUMSUM', 'PRCP_CUMSUM', 'TMIN', 'TMAX', 'ELEVATION','DAY_SIN', 'DAY_COS']]\n",
    "ds2 = xr.open_dataset(base + '/snowcover_june_30_2025.nc')\n",
    "ds3 = xr.open_dataset(base +  '/lai_june_30_2025.nc').sel(XTIME=slice(\"2005-10-01\", \"2016-09-30\"))\n",
    "ds2['XTIME'] = pd.to_datetime(ds2['XTIME'].values)\n",
    "\n",
    "\n",
    "data = xr.merge([ds1, ds2, ds3])\n",
    "data = data.rename({\"snow_presence\": \"BINARY_SNOW_CLASS\"})\n",
    "\n",
    "# ------------------ Data Splitting ------------------\n",
    "split = split_by_time(data)\n",
    "\n",
    "# ------------------ Normalization ------------------\n",
    "variables = ['SNOWNC_CUMSUM', 'PRCP_CUMSUM', 'TMIN', 'TMAX','ELEVATION', 'BINARY_SNOW_CLASS', 'LAI','DAY_SIN', 'DAY_COS']\n",
    "normalizer = XarrayNormalizer(split['train'])\n",
    "train_features_norm = normalizer.fit_transform(\n",
    "    variables=variables, \n",
    "    method=\"minmax\", \n",
    "    save_scaler_path= base + \"/scalers/scalers.pkl\"\n",
    ")\n",
    "\n",
    "normalizer_test = XarrayNormalizer(split['test'])\n",
    "val_features_norm = normalizer_test.transform(\n",
    "    variables=variables,\n",
    "    load_scaler_path= base + \"/scalers/scalers.pkl\"\n",
    ")\n",
    "\n",
    "# ------------------ Target Normalization ------------------\n",
    "target_data = xr.open_dataset(base + '/wrf_target_june_30_2025.nc')\n",
    "split_target = split_by_time(target_data)\n",
    "\n",
    "target_normalizer_train = XarrayNormalizer(split_target['train'])\n",
    "train_target_norm = target_normalizer_train.fit_transform(\n",
    "    variables=['SNOW'],\n",
    "    method=\"minmax\",\n",
    "    save_scaler_path=base + \"/scalers/target_scalers.pkl\"\n",
    ")\n",
    "\n",
    "target_normalizer_test = XarrayNormalizer(split_target['test'])\n",
    "val_target_norm = target_normalizer_test.transform(\n",
    "    variables=['SNOW'],\n",
    "    load_scaler_path=base +\"/scalers/target_scalers.pkl\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f691ada-c257-4702-bc5d-2fc1f3d595a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_order = ['SNOWNC_CUMSUM', 'PRCP_CUMSUM', 'TMIN', 'TMAX','ELEVATION', 'BINARY_SNOW_CLASS', 'LAI','DAY_SIN', 'DAY_COS']\n",
    "\n",
    "test_dataset = SweDataset(val_features_norm, val_target_norm, sequence_length, channel_order)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336385f-fb20-4370-a260-c5dc26567ee6",
   "metadata": {},
   "source": [
    "# Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e3a5fc-8494-41c7-9145-bc5f11d3ae7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d4b4555-0be8-41f1-af65-e5a0670c8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '../saved_models/WRF_MODIS_STATIC_v2.pth'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e153c6-e861-4ada-96e7-72af190d6b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SWE_NET(input_dim=9, hidden_dim=64, kernel_size=(3, 3),height=390, width=348, dropout_rate=0.3).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdba96-a2f1-4dff-aba5-a3ae87658d8c",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31017d60-3af6-4a16-bb4a-6dae8fb5f63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 361/361 [00:27<00:00, 13.32it/s]\n"
     ]
    }
   ],
   "source": [
    "conf_path = base + \"/scalers/target_scalers.pkl\"\n",
    "unscaled_preds = unscale_pred(model,test_loader, conf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb2d1d08-7c28-40f3-89d8-74754ad2d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "static = xr.open_dataset('/bsuscratch/stanleyakor/uppercolorado/static_inputs/wrfout_d02_2000-04-08_00:00:00').isel(Time=0)\n",
    "lat = static.XLAT.values[:, 0]\n",
    "lon = static.XLONG.values[0, :]\n",
    "start_date = f'2015-10-{sequence_length + 1}'\n",
    "end_date = '2016-09-30'\n",
    "output_file = '../data/WRF_MODIS_STATIC_v2_PREDITICTION.nc'\n",
    "\n",
    "write_to_netcdf(output_file, start_date, end_date, lat, lon, unscaled_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
